{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Привет, это базовый пример использования библиотеки [Signess](https://github.com/ElishaFlacon/signess/tree/main/example/datasets)\n",
        "\n",
        "Для начала нужно установить саму библиотеку:"
      ],
      "metadata": {
        "id": "Ww_i9Zr1rBDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install signess"
      ],
      "metadata": {
        "id": "2rEJqHOHq4zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем объект `Dataset`, который будет использоваться для автоматической сборки датасета. Для этого передаем в него объекты `autograph` (для работы с областью обрезанного изображения подписи) и `document`\n",
        "(для непосредственной работы с документами), где при необходимости указываются дополнительные параметры:\n",
        "- Autograph:\n",
        "  - color_low - нижняя граница hsv цвета, по которому находится цветная печать и подпись, по стандарту [0, 50, 0]\n",
        "  - color_hight верхняя граница hsv цвета, по которому находится цветная печать и подпись, по стандарту [255, 255, 255]\n",
        "  - blur - насколько сильно будет размываться изображение, чем сильнее размытие, тем сильнее печать становиться более круглой, что упростит ее нахождение и удаление, по стандарту (3, 3)\n",
        "  - min_radius - минимальный радиус для удаления окружности (печати), по стандарту 80\n",
        "  - max_radius - максимальный радиус для удаления окружности (печати), по стандарту 200\n",
        "  - precent_expansion - увеличение области удаления окружности (печати), чем больше значение, тем более большой круг вырежеться, если 0 - то будет окружность будет вырезана четко по контуру, оставляя небольшие следы из пикселей, по стандарту 0.15\n",
        "  - pixel_thickness - ширина пикселей, чем больше - тем меньше шанс, что подпись разорвертся, но при этом у выходного изображения будут широкие пиксели\n",
        "  - size - размер выходного изображения, по стандарту (256, 256)\n",
        "\n",
        "- Document:\n",
        "  - result_path - путь для сохранения всех обработанных файлов, по стандарту 'result',\n",
        "  - result_autographs - путь для сохранения готовых подписей, по стандарту \"result/autographs\",\n",
        "  - result_persons - путь для сохранения индексированных людей которым принадлежит подпись, по стандарту \"result/persons.csv\",\n",
        "  - result_filenames - путь для сохранения имен обработанных файлов, по стандарту \"result/filenames.csv\",\n",
        "  - result_trash - путь для сохранения бракованных файлов, по стандарту \"result/trash.csv\",\n",
        "  - result_temp - путь для сохранения временных файлов, по стандарту \"result/temp\",\n",
        "  - output_picture_type - формат сохранения файлов, по стандарту \"png\",\n",
        "  - grouping - будут ли подписи группироваться по человеку, по стандарту False\n",
        "\n",
        "`path_to_data` — это путь к директории датасета `base`, его можно получить из репозитория [Signess](https://github.com/ElishaFlacon/signess), для этого необходимо:\n",
        "*   клонировать репозиторий [Signess](https://github.com/ElishaFlacon/signess);\n",
        "*   получить из репозитория директорию `datasets`, она находится в директории `exapmle`;\n",
        "*   загрузить директорию `datasets` к себе на [Google Drive](https://google.com/drive).\n",
        "\n",
        "*Не забываем подключить [Google Drive](https://google.com/drive) к этому [Colab](https://colab.research.google.com/drive/1y3O0GpI3eiRyukHsi1wMb7GeCacmVfMA).*\n",
        "\n",
        "Генерация датасета происходит с помощью метода `.generate`, из документов, полученных в предыдущем шаге, то есть из документов `base`.\n"
      ],
      "metadata": {
        "id": "SuPnmHu18EmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from signess.dataset import Dataset\n",
        "from inskrib.autograph import Autograph\n",
        "from inskrib.documents import Document\n",
        "\n",
        "autograph = Autograph(size=(380, 380))\n",
        "document = Document()\n",
        "\n",
        "path_to_data = \"/content/drive/MyDrive/datasets/base\"\n",
        "\n",
        "ds = Dataset(autograph, document)\n",
        "\n",
        "path_to_dataset = ds.generate(path_to_data)\n",
        "print(path_to_dataset)"
      ],
      "metadata": {
        "id": "fHzqfS6w3pp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В результате генерации датасета, получаем путь `path_to_dataset` до файла с расширением `.npz` содержащего готовый датасет в формате [numpy](https://github.com/numpy/numpy) массива."
      ],
      "metadata": {
        "id": "G90cqaCH9tdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем объект нейронной сети `FedotCNN`, который использует библиотеку [FEDOT](https://github.com/aimclub/FEDOT) - open-source фреймворка автоматического машинного обучения (AutoML), позволяющего автоматически создавать и оптимизировать цепочки задач (пайплайны) машинного обучения или отдельные их элементы.\n"
      ],
      "metadata": {
        "id": "Iusr7cOl9zQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from signess.network import FedotCNN\n",
        "\n",
        "network = FedotCNN()"
      ],
      "metadata": {
        "id": "RtPjb5519LCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Передаем полученный путь `path_to_dataset` до датасета (`.npz` файла), на котором будет обучаться модель, в метод `.load_dataset`, который распакует и преоразует данные для их использования в модели.\n"
      ],
      "metadata": {
        "id": "Ja7XyAsu8Dga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = network.load_dataset(path_to_dataset)"
      ],
      "metadata": {
        "id": "rMOiCw18-Mva"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучаем модель, для этого в метод `.train` передаем датасет и количество эпох."
      ],
      "metadata": {
        "id": "dzcud51D-P0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network.train(dataset, 5)"
      ],
      "metadata": {
        "id": "TPBiFL-S-gQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Делаем предсказания с помощью обученной модели для готового датасета, для этого в метод `.predict` передадим датасет."
      ],
      "metadata": {
        "id": "YpCm2ifW-oib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicts = network.predict(dataset)\n",
        "print(predicts)"
      ],
      "metadata": {
        "id": "KFn49JUD_FAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получаем результат предсказаний."
      ],
      "metadata": {
        "id": "uYxG3sDL_ir7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь сделаем предсказание (классификацию) для одного изображения.\n",
        "\n",
        "С использованием метода `.get_clear_autograph`, в который мы передаём путь до документа `path_to_picture` (исходное изображение), получаем готовую обрезанную подпись из документа. Подготовленная область с подписью понадобится для её классификации, совершаемой вызовом `.classify`, который принимает 2 параметра — путь до обработанной подписи и путь до датасета (до сформированного .npz файла).\n"
      ],
      "metadata": {
        "id": "QVY7eeJz-1bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "temp_path = \"/content/temp.png\"\n",
        "path_to_picture = \"/content/drive/MyDrive/datasets/base/person_1/KUG-na-2023-2024-uch.god-IPTI-ot-07.06.2023_1169.png\"\n",
        "\n",
        "picture = autograph.get_clear_autograph(path_to_picture)\n",
        "cv2.imwrite(temp_path, picture)\n",
        "\n",
        "classify = network.classify(temp_path, path_to_dataset)\n",
        "os.remove(temp_path)\n",
        "\n",
        "classify = classify.tolist()\n",
        "classify_class = classify[0].index(max(classify[0])) + 1\n",
        "\n",
        "print(f\"classify: {classify}\")\n",
        "print(f\"classify_class: {classify_class}\")"
      ],
      "metadata": {
        "id": "2Z2-vpNl_XqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получаем предсказание индекса класса, к которому относится это изображение\n",
        "\n",
        "В файле `result/persons.csv` содержится класс и его индекс."
      ],
      "metadata": {
        "id": "MEeA-g8IAGLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраняем модель, в метод `.save` передаем путь сохранения модели `path_to_save`."
      ],
      "metadata": {
        "id": "TofIDDD6ARKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save = \"./model\"\n",
        "network.save(path_to_save)"
      ],
      "metadata": {
        "id": "pDtnmW7LAd9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь сбросим обучение модели с помощью метода `.blunt`."
      ],
      "metadata": {
        "id": "pOZ6-LT-FqMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network.blunt()"
      ],
      "metadata": {
        "id": "yfdY98CsF_64"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь загрузим сохраненную модель с помощью метода `.load` и после загрузки мы сможем ее использовать для решения прикладных задач.\n",
        "\n",
        "*Работает только с версии [FEDOT](https://github.com/aimclub/FEDOT) >= 0.7.3*\n",
        "\n"
      ],
      "metadata": {
        "id": "DCVWuk80AjTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_network = FedotCNN()\n",
        "new_network.load(path_to_save)"
      ],
      "metadata": {
        "id": "_JASdLVrA1aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Это был весь базовый функционал [Signess](https://github.com/ElishaFlacon/signess).\n",
        "\n",
        "<br />\n",
        "<br />\n",
        "<br />\n",
        "<br />\n",
        "<br />\n",
        "\n",
        "Версию библиотеки в форме desktop-приложения можно найти в репозитории проекта [Signess App](https://github.com/ElishaFlacon/signess-app).\\\n",
        "Кроме базового использования в приложении содержится:\n",
        "- получение метрик модели с помощью библиотеки [sklearn](https://github.com/scikit-learn/scikit-learn);\n",
        "- получение имени владельца подписи после классификации из persons.csv файла."
      ],
      "metadata": {
        "id": "7C6gSxWlA5ZZ"
      }
    }
  ]
}